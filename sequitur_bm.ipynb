{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "DESCRIPTION \n",
    "    Utility function that chops a sequence into several reads with bounded random lengths that \n",
    "    have a bounded random overlap\n",
    "INPUT\n",
    "    sequence       | a sequence of characters that will be divided into overlapping subsequences\n",
    "    min_subseq_len | the shortest length a subsequence can have\n",
    "    max_subseq_len | the longest length a subsequence can have\n",
    "    min_overlap    | the shortest overlap two subsequences can share\n",
    "    max_overlap    | the longest overlap two subsequences can share\n",
    "    circularize    | boolean indicating whether to add a random amount of the end of the sequence\n",
    "                   | to the beginning and vice versa\n",
    "    seed           | random seed for the random function for reproducibility\n",
    "OUTPUT\n",
    "    A list of overlapping reads of random bounded size which share a bounded random amount of\n",
    "    overlap\n",
    "'''\n",
    "def generate_reads(sequence,min_subseq_len,max_subseq_len,min_overlap,max_overlap,min_coverage=None,circularise=False,seed=None):\n",
    "    import random\n",
    "\n",
    "    random.seed(seed)\n",
    "    if circularise: sequence = sequence[-random.randint(min_overlap,max_overlap):] + sequence + sequence[:random.randint(min_overlap,max_overlap)]\n",
    "    reads = []\n",
    "    while 1: \n",
    "        start = 0\n",
    "        end = random.randint(min_subseq_len,max_subseq_len)\n",
    "        reads += [sequence[start:end]]\n",
    "        while end < len(sequence):\n",
    "            start = random.randint(end-max_overlap,end-min_overlap)\n",
    "            if (len(sequence) - start)/max_subseq_len < 2:\n",
    "                if (len(sequence) - start)/max_subseq_len < 1:\n",
    "                    end = len(sequence)\n",
    "                else:\n",
    "                    a = 0\n",
    "                    while (len(sequence) - start)/(min_subseq_len+a) > 2: a+=1\n",
    "                    end = random.randint(start+min_subseq_len+a,start+max_subseq_len) \n",
    "            else: end = random.randint(start+min_subseq_len,start+max_subseq_len) \n",
    "            reads += [sequence[start:end]]\n",
    "        if min_coverage is None or len(set(reads))*(sum(len(read) for read in set(reads))/len(set(reads)))/len(sequence) >= min_coverage: return list(set(reads))\n",
    "\n",
    "'''\n",
    "DESCRIPTION \n",
    "    Utility function that creates a random sequence containing only the letters A, T, G, and C\n",
    "INPUT\n",
    "    n          | the length of the sequence\n",
    "    palindrome | a boolean indicating whether the sequence must be a palidrome or not\n",
    "    seed       | random seed for the random function for reproducibility\n",
    "OUTPUT\n",
    "    A random sequence of length n\n",
    "'''\n",
    "def generate_genome_sequence(n,palindrome=False,seed=None):\n",
    "    import random,math\n",
    "    \n",
    "    random.seed(seed)\n",
    "    nucleotides = {1:'A',2:'C',3:'G',4:'T'}\n",
    "    seq = ''\n",
    "    if palindrome: n = math.ceil(n/2)\n",
    "    for _ in range(n):\n",
    "        seq += nucleotides[random.randint(1,4)]\n",
    "    if palindrome: seq += ''.join(reversed(seq[:int(n-math.fmod(n,2))]))\n",
    "    return seq"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequitur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install networkx\n",
    "import networkx as nx\n",
    "from networkx import bipartite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_suffix_array(reads):\n",
    "    suf_arr = []\n",
    "    for read in reads:\n",
    "        read += '$' + str(reads.index(read))\n",
    "        for i in range(len(read)):\n",
    "            if len(read[i:]) < 4: continue \n",
    "            suf_arr += [read[i:]]\n",
    "    suf_arr.sort()\n",
    "    suf_arr_ind = []\n",
    "    for s in range(len(suf_arr)):\n",
    "        suf_arr_ind += [int(suf_arr[s][-1])]\n",
    "        suf_arr[s] = suf_arr[s][:-1]\n",
    "    return suf_arr,suf_arr_ind\n",
    "\n",
    "def build_bipartite_graph(reads,suf_arr=None,suf_arr_ind=None):\n",
    "    if suf_arr is None or suf_arr_ind is None: suf_arr,suf_arr_ind = build_suffix_array(reads)\n",
    "    B = nx.Graph()\n",
    "    for read in reads:\n",
    "        i = suf_arr.index(read+'$') - 1\n",
    "        while read.startswith(suf_arr[i][:-1]):\n",
    "            B.add_edge('^' + reads[suf_arr_ind[i]],read + '$',weight=len(suf_arr[i][:-1]))\n",
    "            B.add_edge('^' + reads[suf_arr_ind[i]],read + '$',weight=len(suf_arr[i][:-1]))\n",
    "            i -= 1\n",
    "    return B\n",
    "\n",
    "def find_path(graph,draw=False):\n",
    "    G_v = nx.DiGraph()\n",
    "    for p,s in nx.maximal_matching(G):\n",
    "        G_v.add_edge(p[1:],s[:-1],weight=nx.get_edge_attributes(G,\"weight\")[(p,s)])\n",
    "    if draw: nx.draw(G_v)\n",
    "    while not nx.is_connected(G_v.to_undirected()):\n",
    "        add_edges = []\n",
    "        remove_edges = []\n",
    "        for node,degree in G_v.in_degree():\n",
    "            if degree == 0:\n",
    "                edges = list(G.edges(node+'$',data=\"weight\"))\n",
    "                edges.sort(key=lambda x: x[-1])\n",
    "                remove_edges += G_v.out_edges(edges[0][1][1:])\n",
    "                add_edges += [(edges[0][1][1:],edges[0][0][:-1],{'weight':edges[0][2]})]\n",
    "        G_v.remove_edges_from(remove_edges)\n",
    "        G_v.add_edges_from(add_edges)\n",
    "        if draw: nx.draw(G_v)\n",
    "    return G_v\n",
    "\n",
    "def sequitur(path):\n",
    "    while path.number_of_nodes() > 1:\n",
    "        path.add_node(list(path.edges)[0][0] + list(path.edges)[0][1][list(path.edges(data='weight'))[0][2]:])\n",
    "        predecessors = list(path.predecessors(list(path.edges)[0][0]))\n",
    "        for pre in predecessors:\n",
    "            path.add_edge(pre,list(path.edges)[0][0] + list(path.edges)[0][1][list(path.edges(data='weight'))[0][2]:],weight=path.edges[pre,list(path.edges)[0][0]]['weight'])\n",
    "            path.remove_edge(pre,list(path.edges)[0][0])\n",
    "        successors = list(path.successors(list(path.edges)[0][1]))\n",
    "        for suc in successors:\n",
    "            path.add_edge(list(path.edges)[0][0] + list(path.edges)[0][1][list(path.edges(data='weight'))[0][2]:],suc,weight=path.edges[list(path.edges)[0][1],suc]['weight'])\n",
    "            path.remove_edge(list(path.edges)[0][1],suc)\n",
    "        path.remove_nodes_from(list(path.edges)[0])\n",
    "    return list(path.nodes())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = 'betty_bought_butter_the_butter_was_bitter_betty_bought_better_butter_to_make_the_bitter_butter_better'\n",
    "reads = ['betty_bought_butter_th',\n",
    "                        'tter_the_butter_was_',\n",
    "                              'he_butter_was_bitter_',\n",
    "                                         'as_bitter_betty_bought',\n",
    "                                                     'tty_bought_better_butter_t',\n",
    "                                                                     'r_butter_to_make_the_',\n",
    "                                                                                   'ke_the_bitter_butter_better']\n",
    "\n",
    "G = build_bipartite_graph(reads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = find_path(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'betty_bought_butter_the_butter_was_bitter_betty_bought_better_butter_to_make_the_bitter_butter_better'"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequitur(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = 'you say hello world, i bellow go to hell'\n",
    "reads = ['you say hel',\n",
    "            ' say hello wo',\n",
    "                    'lo world, i be',\n",
    "                          'ld, i bellow go t',\n",
    "                                    'ow go to hell']\n",
    "sequitur = Sequitur(reads,assemble=True)\n",
    "sequitur.sequence == sequence if type(sequitur.sequence) is str else all(s in sequence for s in sequitur.sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = 'she_sells_sea_shells_on_the_sea_shore'\n",
    "reads = ['she_sells_s',\n",
    "               'lls_sea_shel',\n",
    "                    'ea_shells_o',\n",
    "                       'shells_on_the_s',\n",
    "                                  'he_sea_s',\n",
    "                                      'ea_shore']\n",
    "sequitur = Sequitur(reads,assemble=True)\n",
    "sequitur.sequence == sequence if type(sequitur.sequence) is str else all(s in sequence for s in sequitur.sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "successes = 0\n",
    "n = 1\n",
    "for seed in range(n):   \n",
    "    # sequence = generate_genome_sequence(10000,seed=seed)\n",
    "    # reads = generate_reads(sequence,250,500,50,100,seed=seed)\n",
    "    sequitur = Sequitur(reads,assemble=True)\n",
    "    s = '| Seed: ' + str(seed) + ' | '\n",
    "    if type(sequitur.sequence) is str and sequitur.sequence == sequence:\n",
    "        s+='SUC | ' + str(sequitur.sequence) + ' == ' + sequence\n",
    "        successes+=1\n",
    "    elif type(sequitur.sequence) is list and all(s in sequence for s in sequitur.sequence):\n",
    "        s+='PAR | ' + str(sequitur.sequence) + ' ~~ ' + sequence\n",
    "        successes+=0.5\n",
    "    else: s+='FAI | ' + sequitur.sequence + ' != ' + sequence\n",
    "    print(s)\n",
    "    print('-----------------------------------------')\n",
    "print('ACCURACY: '+str((successes/n)*100)+'%')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    SUC: returns the target sequence fully reconstructed\n",
    "    PAR: returns contigs all of which exist in the target sequence (consider coverage?)\n",
    "    FAI: returns a full sequence that is incorrectly reconstructed or a set of contigs where at least one is not found in the target sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = generate_genome_sequence(10000,seed=0)\n",
    "reads = generate_reads(sequence,250,500,50,100,seed=0)\n",
    "reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequitur = Sequitur(reads,assemble=True)\n",
    "sequitur.sequence,sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequitur.sequence[sequitur.sequence.find('TTAGTTGTGCCGCAGCGAAGTA'):] in sequence,\\\n",
    "sequitur.sequence[:sequitur.sequence.find('TTAGTTGTGCCGCAGCGAAGTA')] in sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = generate_genome_sequence(10000,palindrome=True,seed=0)\n",
    "reads = generate_reads(sequence,250,500,50,100,seed=0)\n",
    "reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequitur = Sequitur(reads,assemble=True)\n",
    "sequitur.sequence,sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install Bio\n",
    "from Bio import SeqIO, Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for record in SeqIO.parse(\"data/input/Raphanus sativus_NC_018551.1.fasta\",'fasta'):\n",
    "    sequence = record.seq\n",
    "    # print(record)\n",
    "    # break\n",
    "reads = generate_reads(sequence,250,250,50,50,min_coverage=None,seed=0)   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "38731f125b301d8f0df7c54051f2a9a4c898c9398d16ef376d9fb7d661d33405"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
